##################################################################
#
# Code generated by Ben Snodgrass.
# This was done largely during an LMS Undergraduate Research Bursary from July to August in 2021.
# Work was ongoing until December 2022.
#
##################################################################

import numpy as np
import copy
from numpy import linalg as la
import time
import random
from random import random as rand
from matplotlib import pyplot as plt
import math

inf = float('inf')

##################################################################

# General notes:
# All functions should be able to take matrix inputs as either NumPy arrays or list of lists.
# All functions return any matrices as NumPy arrays, unless otherwise stated.

##################################################################
#
# Functions related to graphs and their adjacency matrices
#
##################################################################

# 'onespheres' computes the one spheres of each of the vertices of a combinatorial graph.
#
# Input: 
# A: adjacency matrix of the graph with n vertices.
#
# Output:
# onesps: a list of length n+1 of lists with:
# - onesps[i] a list of all vertices adjacent to vertex i for i < n.
# - onesps[-1] = onesps[n] is a list of length n with entries equal to the combinatorial degree of each vertex.
def onespheres(A):
    A = np.array(A)
    s = len(A)
    onesps = [[] for i in range(s)]
    for i in range(s):
        for j in range(s):
            if A[i, j] != 0:
                onesps[i].append(j)
    onesps.append([len(onesps[i]) for i in range(s)])
    return onesps

# 'rand_adj_mat' returns an adjacency matrix representing a random graph with n vertices.
# The probability of two given vertices being connected is set manually.
# The graph can be required to be connected.
#
# Input:
# n: the number of vertices.
# p: the probability of two arbitrary vertices being connected directly by an edge.
# connected: if connected == True, the resulting graph will be connected.
# mixed: if mixed == True, then the graph may be mixed, i.e. the adjacency matrix may not be symmetric.
#
# Output:
# random adjacency matrix
def rand_adj_mat(n, p, connected=False, mixed=False):
    A = np.zeros((n, n), dtype=int)
    stop = False
    if mixed == False:
        while stop == False:
            for i in range(n):
                for j in range(i):
                    A[i, j] = random.choices([0, 1], [1-p, p])[0]
                    A[j, i] = A[i, j]
            if connected == True:
                stop = is_connected(A)
            else:
                stop = True
    else:
        while stop == False:
            for i in range(n):
                for j in range(i):
                    A[i, j] = random.choices([0, 1], [1-p, p])[0]
                    A[j, i] = random.choices([0, 1], [1-p, p])[0]
            if connected == True:
                stop = is_connected(A)
            else:
                stop = True
    return A
    
# 'complete' produces the adjacency matrix of the complete garph with n vertices.
#
# Input:
# n: number of vertices in complete graph.
#
# Output:
# adjacency matrix of complete graph with n vertices.
def complete(n):
    A = np.ones((n, n), dtype=int)
    for i in range(n):
        A[i, i] = 0
    return A

# 'path' compiles an adjacency matrix of the path with n vertices.
#
# Input:
# n: the number of vertices of the required path.
#
# Output:
# Adjancency matrix of a path with n vertices.
def path(n):
    A = np.zeros((n, n), dtype=int)
    for i in range(n-1):
        A[i, i+1] = 1
        A[i+1, i] = 1
    return A

# 'cycle' compiles an adjacency matrix of the cycle with n vertices.
#
# Input:
# n: the number of vertices of the required cycle.
#
# Output:
# Adjancency matrix of a cycle with n vertices.
def cycle(n):
    A = path(n)
    A[0, n-1] = 1
    A[n-1, 0] = 1
    return A
    
# 'wedge_sum' identifies ('glues') two specified vertices from two separate graphs.
# This means that the two graphs are connected at a shared vertex.
#
# Input:
# A and B: adjacency matrices of graphs to be glued.
# i and j: vertex numbers of the vertices in A and B respectively at which the graphs should be glued.
#
# Output:
# adjacency matrix of the wedge graph.
def wedge_sum(A, B, i, j):
    m = len(A)
    n = len(B)
    row = np.delete(B[j], j)
    B_prime = np.delete(np.delete(B, j, 0), j, 1)
    top_right = np.zeros((m, n-1), dtype=int)
    top_right[i] = row
    bottom_left = np.transpose(top_right)
    upper = np.concatenate((A, top_right), axis=1)
    lower = np.concatenate((bottom_left, B_prime), axis=1)
    return np.concatenate((upper, lower))

# 'bridge_at' connects two graphs at specified vertices by a single edge.
#
# Inputs:
# A: adjacency matrix of one graph, B: adjacency matrix of the other.
# i: index of vertex in A at which connection should be.
# j: index of vertex in B at which connection should be.
#
# Output:
# adjacency matrix of the connected graph as Numpy array.
def bridge_at(A, B, i, j):
    m = len(A)
    n = len(B)
    A = np.concatenate((np.concatenate((A, np.zeros((n, m), dtype=int))), 
                        np.concatenate((np.zeros((m, n), dtype=int), B))), axis=1)
    A[i, m+j] = 1
    A[m+j, i] = 1
    return A
    
# 'hypercube' produces the adjacency matrix of the n-dimensional hypercube.
#
# Input:
# n: dimension of the hypercube.
#
# Output:
# adjacency matrix of n-cube.
def hypercube(n):
    A = np.array([[0, 1], [1, 0]], dtype=int)
    i = 2
    while i <= n:
        A = np.concatenate((np.concatenate((A, np.identity(2**(i-1), dtype=int))), 
                            np.concatenate((np.identity(2**(i-1), dtype=int), A))), axis=1)
        i += 1
    return A

# 'cart_prod' returns an adjacency matrix of the Cartesian product of two graphs.
#
# Input:
# A and B: adjacency matrices of graphs of which the Cartesian product is to be taken.
#
# Output:
# adjacency matrix of the product graph
def cart_prod(A, B):
    m = len(A)
    n = len(B)
    return kronecker(A, np.identity(n, dtype=int))+kronecker(np.identity(m, dtype=int), B)

# 'kronecker' returns the Kronecker product of two matrices.
# For these purposes, the matrices will usually be adjacency matrices.
#
# Input:
# A and B: matrices to the Kronecker product of.
#
# Output:
# Kronecker product matrix
def kronecker(A, B):
    A = np.array(A)
    B = np.array(B)
    m = len(A)
    n = len(B)
    C = [_ for _ in range(m)]
    for i in range(m):
        C[i] = A[i, 0]*B
        for j in range(1, m):
            C[i] = np.concatenate((C[i], A[i, j]*B), axis=1)
    D = C[0]
    for i in range(1, m):
        D = np.concatenate((D, C[i]))
    return D

##################################################################
#
# Functions related to weighting schemes
#
##################################################################


# 'randomizer' creates a random, non-degenerate Markov weighting scheme for an adjacency matrix A.
# Whether the vertices have a non-zero laziness is set manuallly.
#
# Input:
# A: adjacency matrix of graph.
# threshold: minimum allowed value for a transition rate.
# laziness: If laziness == True, the vertices have randomized non-zero laziness.
# If laziness == False, all vertices have zero laziness.
# 
# Output:
# randomized transition rate scheme in matrix.
def randomizer(A, threshold=0.001, laziness=False):
    valid = False
    s = len(A)
    A = np.array(A)
    isolated = []
    neighbours = np.matmul(A, np.ones(s))
    for i in range(s):
        if neighbours[i] == 0:
            isolated.append(i)
    while valid == False:
        valid = True
        P = np.zeros((s, s))
        if laziness == True:
            for i in range(s):
                P[i, i] = rand()
        for i in isolated:
            P[i, i] = 1
        for i in range(s):
            for j in range(s):
                if A[i, j] != 0:
                    P[i, j] = rand()
        degree = np.matmul(P, np.ones(s))
        for i in range(s):
            P[i] /= degree[i]
        for i in range(s):
            for j in range(s):
                if P[i, j] != 0 and P[i, j] < threshold:
                    valid = False
    return P

# 'srw' produces the simple random walk weighting scheme for a graph.
# This means transition rates emanating from a vertex are equal to 1/n (n=vertex's combinatorial degree).
# Laziness can be incorporated as described below.
#
# Input:
# A: adjacency matrix or graph.
# If a vertex x has combinatorial degree n:
# laziness == True: laziness = outgoing transition rates from x = 1/(n+1).
# laziness == False: laziness = 0, outgoing transition rates from x = 1/n.
#
# Output:
# simple random walk weighting scheme in matrix as NumPy array.
def srw(A, laziness=False):
    r = len(A)
    P = np.array(A, dtype=float)
    q = np.matmul(P, np.ones(r))
    if laziness == False:
        for i in range(r):
            if q[i] != 0:
                P[i] /= q[i]
            else:
                print("Warning: vertex {} is isolated".format(i))
                P[i, i] = 1
        return P
    if laziness == True:
        for i in range(r):
            for j in range(r):
                P[i, j] /= q[i] + 1
        P += np.diag(np.reciprocal(q+np.ones(r)))
        return P
                
#'cart_prod_prob' returns a weighting scheme on the Cartesian product of two given weighted graphs.
# It uses two parameters 'p' and 'q' that are weightings for the two graphs in the calculation, with p+q = 1.
#
# Input:
# P and Q: matrices of transition rates for the two graphs.
# p and q: weightings for the two graphs in the calculation.
# 
# Output:
# Matrix of transition rates corresponding to the product graph.
def cart_prod_prob(P, Q, p, q):
    m = len(P)
    n = len(Q)
    return p*kronecker(P, np.identity(n, dtype=int))+q*kronecker(np.identity(m, dtype=int), Q)

##################################################################
#
# Functions testing combinatorial and weighted graphs
#
##################################################################

# 'is_connected' determines if an adjacency matrix represents a connected graph.
#
# Input:
# A: adjacency matrix of the graph.
# 
# Output:
# True if A represents a connected adjacency matrix, False otherwise.    
def is_connected(A):
    A = np.array(A)
    n = len(A)
    A_powers = [A]
    for _ in range(n-2):
        A_powers.append(np.matmul(A, A_powers[-1]))
    B = sum(A_powers)
    for i in range(n):
        for j in range(n):
            if B[i, j] == 0:
                return False
    return True

# 'is_weakly_connected' determines if a matrix of transition rates represents a weakly connected graph.
#
# Input:
# P: the matrix of transition rates.
# threshold: any transition rates less than this will be considered as zero.
# viz. P_{xy}, P_{yx} < threshold, (x, y) will not be counted as an edge in the connectedness calculation.
#
# Output:
# True if A represents a weakly connected adjacency matrix, False otherwise.
def is_weakly_connected(P, threshold=0.001):
    P = np.array(P)
    n = len(P)
    A = np.zeros((n, n), dtype=int)
    for i in range(n):
        for j in range(i):
            if P[i, j] > threshold or P[j, i] > threshold:
                A[i, j] = 1
                A[j, i] = 1
    return is_connected(A)

# 'is_totally_degenerate' determines a weighted graph is (numerically) totally degenerate. 
#
# Inputs:
# A: adjacency matrix of the graph.
# P: matrix of transition rates.
# threshold: Transition rates p_{xy} are considered zero if p_{xy} < threshold.
# 
# Output:
# Returns 'True' if the graph is totally degenerate, returns 'False' if not.
def is_totally_degenerate(A, P, threshold=0.001):
    n = len(A)
    M = np.zeros((n, n), dtype=int)
    t_d = True
    i = 0
    while t_d == True and i < n:
        for j in range(i):
            if A[i, j] == 1 and A[j, i] and P[i, j] > threshold and P[j, i] > threshold:
                t_d = False
            elif A[i, j] == 1 and A[j, i] == 0 and P[i, j] > threshold:
                t_d = False
            elif A[i, j] == 0 and A[j, i] == 1 and P[j, i] > threshold:
                t_d = False
        i += 1
    return t_d

# 'is_markovian' determines if a given selection of transition rates satisfy the Markovian property.
#
# Inputs:
# P: matrix of transition rates.
# norm_tolerance: numerical limit on the largest admissable numerical deviation from the Markov property.
# vis. if |-1 + p_{xx} + \sum_{y~x} p_{xy}| > norm_tolerance for a vertex x, is_markovian returns False.
# 
# Output:
# 'True' if the graph satisfies the Markovian property, 'False' if not.
def is_markovian(P, norm_tolerance=0.001):
    s = len(P)
    norm = np.matmul(P, np.ones(s))
    for i in range(s):
        if abs(norm[i]-1) > norm_tolerance:
            return False
    return True 

# 'is_curvature_sharp' determines if a given selection of transition rates on a graph is curvature sharp.
#
# Inputs:
# A: adjacency matrix of graph.
# P: matrix of transition rates.
# norm_tolerance: numerical limit on the largest admissable numerical deviation from the Markov property.
# vis. if |-1 + p_{xx} + \sum_{y~x} p_{xy}| > norm_tolerance for a vertex x, is_markovian returns False.
# threshold: Sets a numerical limit on how far the graph may deviate from being curvature sharp.
#
# Output:
# 'True' if the graph is (numerically) curvature sharp, 'False' if not.
def is_curvature_sharp(A, P, norm_tolerance=0.001, threshold=0.001):
    s = len(A)
    A = np.array(A)
    P = np.array(P)
    norm = np.matmul(P, np.ones(s))
    for i in range(s):
        if is_markovian(P, norm_tolerance) == False:
            print("The transition rates do not satisfy the Markov property")
            return None
    onesps = onespheres(A)
    differential = Pvecs_prime(A, P, K_inf, onesps)
    for vertex in range(s):
        for edge in range(onesps[-1][vertex]):
            if abs(differential[vertex][edge]) > threshold:
                return False
    return True

# 'equilibrium_type' determines the stability of a curvature sharp configuration of transition rates
#
# Inputs:
# A: adjacency matrix of the graph.
# P: matrix of transition rates of the graph.
# eigenvalues: If eigenvalues == True, returns eigenvalues of the Jacobi matrix.
# jacobi_matrix: If jacobi_matrix == True, returns the Jacobi matrix of the equilibrium.
# norm_tolerance: numerical limit on the largest admissable numerical deviation from the Markov property.
#     vis. if |-1 + p_{xx} + \sum_{y~x} p_{xy}| > norm_tolerance for a vertex x, is_markovian returns False.
# threshold: The code calculates the largest real part of an eigenvalue of the Jacobi matrix.
#            Only if this has absolute value less than threshold does the function state the equilibrium type.
#            Otherwise, it returns 0 (undetermined).
#
# Outputs:
# First output: If asymptotically stable, -1. If unstable, +1. If undetermined, 0.
# Second output: The eigenvalues of the Jacobi matrix, if eigenvalues == True.
# Third output: The Jacobi matrix itself, if jacobi_matrix == True.
# If either 'eigenvalues' or 'jacobi_matrix' are set to be False, then None is returned in their place.
def equilibrium_type(A, P, eigenvalues=False, jacobi_matrix=False, norm_tolerance=0.001, threshold=0.001):
    A = np.array(A)
    P = np.array(P)
    cs = is_curvature_sharp(A, P, norm_tolerance, threshold)
    if cs == None:
        print("This graph does not satisfy the Markovian property")
        return None, None, None
    if cs == False:
        print("This graph is not curvature sharp.")
        return None, None, None
    onesps = onespheres(A)
    n = len(A)
    D_x = np.array([1-P[x, x] for x in range(n)])
    P_traceless = P-np.diag([P[x, x] for x in range(n)])
    edges = []
    for i in range(n):
        for j in onesps[i]:
            edges.append([i, j])
    e = len(edges)
    indices = []
    q = -1
    for i in range(n):
        q += onesps[-1][i]
        indices.append(q)
    ess_inds = [i for i in range(e)]
    for ind in indices:
        ess_inds.remove(ind)
    ess_edges = []
    for edge in edges:
        if edges.index(edge) not in indices:
            ess_edges.append(edge)
    m = len(ess_edges)
    B = np.zeros((e, e), dtype=float)
    P_sum_x = np.matmul(P_traceless, np.transpose(A))
    P_traceless_2 = np.matmul(P_traceless, P_traceless)
    double_sum = np.matmul(P_traceless_2, np.transpose(A))
    for edge in edges:
        i = edges.index(edge)
        x = edge[0]
        y = edge[1]
        B[i, i]=-4*P[y, x]-P[y, y]-2*P_sum_x[y, x]+1/D_x[x]*(4*P[x, y]*P[y, x]+4*P_traceless_2[x, x]
                                                             +P[x, y]*P_sum_x[y, x]+double_sum[x, x])
        B[i, edges.index([y, x])] = 4*P[x, y]*(1/D_x[x]*P[x, y]-1)
        for y_1 in onesps[x]:
            if y_1 != y:
                B[i, edges.index([x, y_1])] = (4/D_x[x]*P[x, y]*P[y_1, x]
                                               +1/D_x[x]*P[x, y]*(P_sum_x[y_1, x])+P[y_1, y])
                B[i, edges.index([y_1, x])] = 4/D_x[x]*P[x, y]*P[x, y_1]
                if [y, y_1] in edges:
                    B[i, edges.index([y, y_1])] = P[x, y]*(1/D_x[x]*P[x, y]-2)
                    B[i, edges.index([y_1, y])] = P[x, y_1]*(1/D_x[x]*P[x, y]+1)
                for y_2 in onesps[x]:
                    if [y_1, y_2] in edges:
                        if y_2 != y and y_2 != y_1:
                            B[i, edges.index([y_1, y_2])] = 1/D_x[x]*P[x, y]*P[x, y_1]
    DF = np.zeros((m, m), dtype=float)

    for j in range(m):
        k_l = indices[0]
        for k in range(m):
            for a in range(len(indices)-1):
                if indices[a] <= k+a < indices[a+1]:
                    k_l = indices[a+1]
            DF[j, k] = B[ess_inds[j], ess_inds[k]]-B[ess_inds[j], k_l]
    eigenvals = la.eigvals(DF)
    max_real_part_eig = max([eigenvals[i].real for i in range(m)])
    if max_real_part_eig > threshold:
        res = 1
    elif max_real_part_eig < -threshold:
        res = -1
    else:
        res = 0
        
    if res == 1:
        print("There is an eigenvalue with positive real part, implying instability.")
    elif res == -1:
        print("All real parts of eigenvalues negative, implying asymptotic stability.")
    else:
        print("All eigenvalues are either negative or within 'threshold' of 0, so stability is undetermined.")
    
    if jacobi_matrix == True and eigenvalues == True:
        return res, eigenvals, DF
    elif jacobi_matrix == True and eigenvalues == False:
        return res, None, DF
    elif jacobi_matrix == False and eigenvalues == True:
        return res, eigenvals, None
    else:
        return res, None, None

##################################################################
#
# Function curv_flow and relevant computational functions
#
##################################################################


# 'Pvecs_to_P' is a function used internally in the curvature flow functions.
def Pvecs_to_P(Pvecs, s, onesps):
    P = np.zeros((s, s))
    for i in range(s):
        for j in range(s):
            if j in onesps[i]:
                P[i, j] = Pvecs[i][onesps[i].index(j)]
    return P

# 'Pvecs_prime' is a function used internally in the curvature flow functions.
# It calculates the derivatives w.r.t. time of each transition rate in the graph.
#
# Inputs:
# A: adjacency matrix of graph
# P: matrix of transition rates
# C: half the coefficient of p_{xy}(t) in the differential equation for p_{xy}(t).
# onesps: this should be onespheres(A) using 'onespheres' as above.
#
# Output:
# A list with s entries, where s is the number of vertices.
# The ith entry is a NumPy 1 x m matrix.
# Entries equal to the derivatives of the transition rates emanating from that vertex.
def Pvecs_prime(A, P, C, onesps):
    s = len(P)
    P_2 = np.matmul(P, P)
    sum_ = np.matmul(P, np.transpose(A))
    Pvecs0 = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
    derivs = [_ for _ in range(s)]
    coeff = C(A, P)
    for x in range(s):
# minus sign before P[i, i] to cancel two extra P[i, i] from sum_
        _4Q_ones = np.array([P[x, i]*(4*P[i, x]+2*sum_[i, x])-P_2[x, i] for i in onesps[x]], dtype=float)
        derivs[x] = -_4Q_ones+2*coeff[x]*Pvecs0[x]
    return derivs

# 'zeroes' is an option for C_x(t) detailed in the paper with C_x(t) = 0 for all t >= 0.
# It has the superfluous input P to match the arguments of other C_x(t) such as K_inf.
# 
# Inputs:
# A: adjacency matrix of the graph.
# P: matrix of transition rates of the graph.
#
# Output:
# A NumPy 1 x n array with all entries equal to zero, where n is the number of vertices.
def zeroes(A, P):
    return np.zeroes(len(A), dtype=float)

# 'curv_flow' is a fundamental function in this code.
# It computes the curvature flow of a given graph and with its set of initial transition rates.
# It uses the Runge-Kutta method (RK4) to solve the system of ODEs.
# 
# Inputs:
# A: adjacency matrix of the graph.
# P: the matrix of initial transition rates. P[x, y] is the initial transition rate p_{xy}(0).
# t_max: the time until which the programme should run the flow.
# dt: the time increment in the RK4 calculation.
# In most cases, a value of dt = 0.3 is a good compromise between computational effort and accuracy.
# C: as denoted in the paper, representing half the coefficient of p_x(t) in the curvature flow equation.
# Natural choices for C are K_inf and zeros, detailed below.
# norm_tolerance: Artificially renormalizes the code to preserve Markov, if appropriate
# This happens when abs(-1+laziness+outgoing transition rates) > norm_tolerance.
# If it happens, the programme notifies the user in the output box.
#
# Output:
# P_list: a list of the P-matrices at each time increment.
def curv_flow(A, P, t_max, dt=0.3, C=zeroes):
# A gives topology of G
    A = np.array(A, dtype=int)
    P = np.array(P, dtype=float)
    s = len(A)
    onesps = onespheres(A)
    Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
    t = dt
    
    diag = np.diag(P)
            
    P_list = [P]
    
    while t <= t_max+0.00001:
       
        k1 = Pvecs_prime(A, P, C, onesps)

        P2 = P+1/2*dt*Pvecs_to_P(k1, s, onesps)
        k2 = Pvecs_prime(A, P2, C, onesps)
        
        P3 = P+1/2*dt*Pvecs_to_P(k2, s, onesps)
        k3 = Pvecs_prime(A, P3, C, onesps)

        P4 = P+dt*Pvecs_to_P(k3, s, onesps)
        k4 = Pvecs_prime(A, P4, C, onesps)

        Pvecs = [Pvecs[i]+1/6*dt*(k1[i]+2*k2[i]+2*k3[i]+k4[i]) for i in range(s)]

        P = Pvecs_to_P(Pvecs, s, onesps) + np.diag(np.diag(P))
            
        P_list.append(P)
        
        t += dt
        
    return P_list

# norm_curv_flow calculates the solution to the curvature flow of a Markovian chain under the flow.
#
# Inputs:
# A: adjacency matrix of the graph
# P: the matrix of initial transition rates. P[x, y] is the initial transition rate p_{xy}(0).
# t_max: the time at which the calculation stops.
# dt: the time increment in the RK4 calculation.
# In most cases, a value of dt = 0.3 is a good compromise between computational effort and accuracy.
# stoch_corr == True: Numerical deviation of the flow from satisfying the Markovian property is corrected.
#                     This is done by normalizing the transition rates to sum to unity.
# stoch_corr == False: Checks when the numerical deviation exceeds norm_tolerance.
#                      When this occurs, user is asked how the calculation should proceed.
# norm_tolerance: Only relevant if the Markov property should be preserved (C == K_inf).
#                 If the Markov property is violated by more than norm_tolerance, flow may be corrected.
#
# Output:
# First entry: The matrix of transition rates at the time when the flow was deemed to have converged.
# Second entry: The time at which the flow was deemed to have converged.
def norm_curv_flow(A, P, t_max, dt=0.3, stoch_corr=True, norm_tolerance=0.001):
# A gives topology of G
    A = np.array(A, dtype=int)
    P = np.array(P, dtype=float)
    C = K_inf
    s = len(A)
    onesps = onespheres(A)
    Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
    t = dt
    
    diag = np.diag(P)
    
    norm = np.matmul(P, np.ones(s))
    if C == K_inf:
        if is_markovian(P, norm_tolerance) == False:
            print("The initial transition rates do not satisfy the Markov property")
            return None
    ask = True
            
    P_list = [P]
    
    while t <= t_max+0.00001:
        k1 = Pvecs_prime(A, P, C, onesps)

        P2 = P+1/2*dt*Pvecs_to_P(k1, s, onesps)
        k2 = Pvecs_prime(A, P2, C, onesps)
        
        P3 = P+1/2*dt*Pvecs_to_P(k2, s, onesps)
        k3 = Pvecs_prime(A, P3, C, onesps)

        P4 = P+dt*Pvecs_to_P(k3, s, onesps)
        k4 = Pvecs_prime(A, P4, C, onesps)

        Pvecs = [Pvecs[i]+1/6*dt*(k1[i]+2*k2[i]+2*k3[i]+k4[i]) for i in range(s)]

        P = Pvecs_to_P(Pvecs, s, onesps) + np.diag(np.diag(P))

        norm = np.matmul(P, np.ones(s))
        
        if stoch_corr == False:
            Markov = True
            i = 0
            while Markov == True and i < s:
                if abs(norm[i]-1) > norm_tolerance:
                    Markov = False
                i += 1
        
        if stoch_corr == True:
            c = [_ for i in range(s)]
            for i in range(s):
                if diag[i] != 1:
                    c[i] = (norm[i] - diag[i])/(1-diag[i])
            for i in range(s):
                if diag[i] != 1:
                    P[i] /= c[i]
                    P[i, i] = diag[i]
            Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
        
        elif ask == True and Markov == False:
            print()
            print("'norm_tolerance' has been exceeded at one or more vertices, at time t = {}. "
                  "Would you like to: \n A = Stop calculation and return list of P-matrices so far \n "
                  "B = Apply manual normalization now, and apply it again when necessary without asking "
                  "(you will still be notified when it is applied) \n C = Apply manual normalization "
                  "now, and ask again before reapplying it".format(round(t, 2)))
            ans = input("Please enter A, B or C here: ")
            if ans == "A":
                return P_list
            elif ans == "B":
                c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
                for i in range(s):
                    P[i] /= c[i]
                    P[i, i] = diag[i]
                Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
                print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))
                ask = False
            elif ans == "C":
                c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
                for i in range(s):
                    P[i] /= c[i]
                    P[i, i] = diag[i]
                Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
                print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))
            else:
                ans = input("Please enter A, B, or C (in capitals): ")
        
        elif ask == False and Markov == False:
            c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
            for i in range(s):
                P[i] /= c[i]
                P[i, i] = diag[i]
            Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
            print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))

        for i in range(s):
            for j in range(s):
                if P[i, j] < 0:
                    P[i, j] = 0
                    print("")
                    print("Negative rate from vertex {} to {} at time t = {}".format(i, j, round(t, 1)))
                    print("")

                    
        P_list.append(P)
        
        t += dt
        
    return P_list

# norm_curv_flow_lim calculates the limiting matrix of transition rates of a Markovian chain under the flow
# It automatically stops the calculation when equilibrium is considered to have been reached.
# 
# Inputs:
# A: adjacency matrix of the graph
# P: the matrix of initial transition rates. P[x, y] is the initial transition rate p_{xy}(0).
# dt: the time increment in the RK4 calculation.
# In most cases, a value of dt = 0.3 is a good compromise between computational effort and accuracy.
# stoch_corr == True: Numerical deviation of the flow from satisfying the Markovian property is corrected.
#                     This is done by normalizing the transition rates to sum to unity.
# stoch_corr == False: Checks when the numerical deviation exceeds norm_tolerance.
#                      When this occurs, user is asked how the calculation should proceed.
# norm_tolerance: Only relevant if the Markov property should be preserved (C == K_inf).
#                 If the Markov property is violated by more than norm_tolerance, flow may be corrected.
# lim_tolerance: Determines when the flow is considered to have converged.
# Converged if both P(t+10)-P(t) and P(t+20)-P(t) have maximum entry-wise absolute values less than lim_tolerance.
# t_lim: If the flow still has not converged with respect to lim_tolerance by t=t_lim,
# then the calculation stops and the flow is declared not to have converged.
#
# Output:
# First entry: The matrix of transition rates at the time when the flow was deemed to have converged.
# Second entry: The time at which the flow was deemed to have converged.
def norm_curv_flow_lim(A, P, dt=0.3, stoch_corr=True, norm_tolerance=0.001, lim_tolerance=0.001, t_lim=10000):
# A gives topology of G
    A = np.array(A, dtype=int)
    P = np.array(P, dtype=float)
    s = len(A)
    C = K_inf
    onesps = onespheres(A)
    Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
    t = dt
    
    diag = np.diag(P)
    
    norm = np.matmul(P, np.ones(s))
    if C == K_inf:
        if is_markovian(P, norm_tolerance) == False:
            print("The transition rates do not satisfy the Markov property")
            return None
            
    ask = True
            
    P_list = [P]
    
    while t <= t_lim+0.00001:
       
        k1 = Pvecs_prime(A, P, C, onesps)

        P2 = P+1/2*dt*Pvecs_to_P(k1, s, onesps)
        k2 = Pvecs_prime(A, P2, C, onesps)
        
        P3 = P+1/2*dt*Pvecs_to_P(k2, s, onesps)
        k3 = Pvecs_prime(A, P3, C, onesps)

        P4 = P+dt*Pvecs_to_P(k3, s, onesps)
        k4 = Pvecs_prime(A, P4, C, onesps)

        Pvecs = [Pvecs[i]+1/6*dt*(k1[i]+2*k2[i]+2*k3[i]+k4[i]) for i in range(s)]
        
        P = Pvecs_to_P(Pvecs, s, onesps) + np.diag(np.diag(P))

        norm = np.matmul(P, np.ones(s))
        
        if stoch_corr == False:
            Markov = True
            i = 0
            while Markov == True and i < s:
                if abs(norm[i]-1) > norm_tolerance:
                    Markov = False
                i += 1
        
        if stoch_corr == True:
            c = [_ for i in range(s)]
            for i in range(s):
                if diag[i] != 1:
                    c[i] = (norm[i] - diag[i])/(1-diag[i])
            for i in range(s):
                if diag[i] != 1:
                    P[i] /= c[i]
                    P[i, i] = diag[i]
            Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
        
        elif ask == True and Markov == False:
            print()
            print("'norm_tolerance' has been exceeded at one or more vertices, at time t = {}. "
                  "Would you like to: \n A = Stop calculation and return list of P-matrices so far \n "
                  "B = Apply manual normalization now, and apply it again when necessary without asking "
                  "(you will still be notified when it is applied) \n C = Apply manual normalization "
                  "now, and ask again before reapplying it".format(round(t, 2)))
            ans = input("Please enter A, B or C here: ")
            if ans == "A":
                return P_list
            elif ans == "B":
                c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
                for i in range(s):
                    P[i] /= c[i]
                    P[i, i] = diag[i]
                Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
                print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))
                ask = False
            elif ans == "C":
                c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
                for i in range(s):
                    P[i] /= c[i]
                    P[i, i] = diag[i]
                Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
                print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))                
        
        elif ask == False and Markov == False:
            c = [(norm[i] - diag[i])/(1-diag[i]) for i in range(s)]
            for i in range(s):
                P[i] /= c[i]
                P[i, i] = diag[i]
            Pvecs = [np.array([P[i, j] for j in onesps[i]]) for i in range(s)]
            print("Transition rates have been artificially normalized at time t = {}".format(round(t, 2)))
    

        for i in range(s):
            for j in range(s):
                if P[i, j] < 0:
                    P[i, j] = 0
                    print("")
                    print("Negative rate from vertex {} to {} at time t = {}".format(i, j, round(t, 2)))
                    print("")
        
        P_list.append(P)
        
        t_min = 10
        if t > 2*t_min + 1:
            P_list.pop(0)
            
            mat1 = P_list[int(-2*t_min//dt)] - P_list[int(-t_min//dt)]
            mat2 = P_list[int(-2*t_min//dt)] - P_list[-1]
            diff = abs(mat1[0, 0])
            for i in range(s):
                for j in range(s):
                    if abs(mat1[i, j]) > diff:
                        diff = abs(mat1[i, j])
                    if abs(mat2[i, j]) > diff:
                        diff = abs(mat2[i, j])
                        
                    
            if diff < lim_tolerance:
                print("Limit was reached at time t = {}".format(round(t-20, 2)))
                return P_list[int(-2*t_min//dt)], round(t-20, 2)
        
        t += dt
        
    print("Limit was not reached before t = {}. A list containing the final matrix of transition "
          "rates at t=t_lim and t_lim has been returned.")
    
    return P, t_lim

##################################################################
#
# Curvature computation routines
#
##################################################################


# 'curvatures' returns a list of the Bakry-Emery curvatures of all the vertices in the graph

# Input:
# A: adjacency matrix of graph
# P: matrix of transition rates
# N: dimension to be used in curvature calculation.
# onesps: this is onespheres(A) using 'onespheres' as above.
# q: number of vertices in graph.
# If either q or onesps are omitted, the function calcualtes them automatically.

# Output:
# List of curvature values of each vertex, ordered by vertex index.
def curvatures(A, P, N=inf, onesps=[], q=None):
    A = np.array(A)
    P = np.array(P)
    if len(onesps) == 0:
        onesps = onespheres(A)
    if q == None:
        q = len(A)
    
    switch = False
    for i in range(q):
        for j in range(q):
            if A[i, j] != 0 and P[i, j] < 10**(-5):
                P[i, j] = 0
                switch = True
                
    curvlst = []
    P_traceless = P-np.diag(np.diag(P))
    D_x = np.matmul(P_traceless, np.ones(q))
    P_t_2 = np.matmul(P_traceless, P_traceless)
    twosp = np.matmul(A, A)
    for i in range(q):
        for j in range(q):
            if i == j:
                twosp[i, j] = 0
            if A[i, j] == 1:
                twosp[i, j] = 0
            if twosp[i, j] != 0:
                twosp[i, j] = 1
    Z = twosp*P_t_2
    
    if switch == False:
        for i in range(q):
            for j in range(q):
                if twosp[i, j] != 0:
                    Z[i, j] = 1/Z[i, j]
        sum1 = 3/2*np.matmul(P, twosp)
        sum2 = 3/2*np.matmul(P_traceless, A)
        sum3 = 2*np.matmul(Z, np.transpose(np.square(P)))
        sum4 = 2*np.matmul([[[P[i, z]*P[j, z] for z in range(q)] for j in range(q)]
                            for i in range(q)], np.transpose(Z))
        for x in range(q):
            m = onesps[-1][x]
            if m == 0:
                curvlst.append(0)
            else:
                onesp = onesps[x]
                A_N = np.array([[-2/N*(P[x, i]*P[x, j])**0.5 for j in onesp] for i in onesp])
                for i in range(m):
                    A_N[i, i] += (P[x, onesp[i]]+3/2*P[onesp[i], x]-1/2*D_x[x]+sum1[onesp[i], x]
                    +sum2[onesp[i], x]-P[x, onesp[i]]*sum3[x, onesp[i]]+1/2*P_t_2[x, onesp[i]]/P[x, onesp[i]])
                for i in range(m):
                    for j in range(m):
                        if i != j:
                            A_N[i, j] += (P[x, onesp[i]]*P[x, onesp[j]]-P[x, onesp[i]]*P[onesp[i], onesp[j]]
                                          -P[x, onesp[j]]*P[onesp[j], onesp[i]]
                                          -P[x, onesp[i]]*P[x, onesp[j]]*sum4[onesp[i], onesp[j], x])
                            A_N[i, j] /= np.sqrt(P[x, onesp[i]]*P[x, onesp[j]])
                curvlst.append(la.eigvalsh(A_N)[0])

    else:
        for i in range(q):
            for j in range(q):
                if Z[i, j] != 0:
                    Z[i, j] = 1/Z[i, j]
        sum1 = 3/2*np.matmul(P, twosp)
        sum2 = 3/2*np.matmul(P_traceless, A)
        sum3 = 2*np.matmul(Z, np.transpose(np.square(P_traceless)))
        sum4 = 2*np.matmul([[[P[i, z]*P[j, z] for z in range(q)] for j in range(q)] 
                            for i in range(q)], np.transpose(Z))
        for x in range(q):
            m = onesps[-1][x]
            if m == 0:
                curvlst.append(0)
            else:
                onesp = onesps[x]
                Q = np.zeros((m, m))
                for i in range(m):
                    Q[i, i] = 1/2*(P[x, onesp[i]]*(P[x, onesp[i]]+3/2*P[onesp[i], x]-1/2*D_x[x]
                                                   +sum1[onesp[i], x]+sum2[onesp[i], x]
                                                   -P[x, onesp[i]]*sum3[x, onesp[i]])+1/2*P_t_2[x, onesp[i]])
                for i in range(m):
                    for j in range(m):
                        if i != j:
                            Q[i, j] = 1/2*(P[x, onesp[i]]*P[x, onesp[j]]-P[x, onesp[i]]*P[onesp[i], onesp[j]]
                                           -P[x, onesp[j]]*P[onesp[j], onesp[i]]
                                           -P[x, onesp[i]]*P[x, onesp[j]]*sum4[onesp[i], onesp[j], x])
                        
                dim_mat = 1/N*np.array([[P[x, i]*P[x, j] for j in onesp] for i in onesp])
                Q_N = Q - dim_mat
                gamma = 1/2*np.diag([P[x, i] for i in onesp])               
                
                error = 10**(-5)
                
                pos_def = True
                if N >= 2:
                    K0 = -min(D_x+np.diag(P))+1
                else:
                    K0 = -min(D_x+np.diag(P))+1-2*D_x[x]/N                
                
                while pos_def == True:
                    if la.eigvalsh(Q_N - K0*gamma)[0] >= -error:
                        K0 += 1
                    else:
                        pos_def = False
                                
                pos_def = True
                K1 = K0 - 9/10
                while pos_def == True and K1 <= K0:
                    if la.eigvalsh(Q_N - K1*gamma)[0] >= -error:
                        K1 += 1/10
                    else:
                        pos_def = False
                        
                pos_def = True
                K2 = K1 - 9/100
                while pos_def == True and K2 <= K1:
                    if la.eigvalsh(Q_N - K2*gamma)[0] >= -error:
                        K2 += 1/100
                    else:
                        pos_def = False
                        
                pos_def = True
                K3 = K2 - 9/1000
                while pos_def == True and K3 <= K2:
                    if la.eigvalsh(Q_N - K3*gamma)[0] >= -error:
                        K3 += 1/1000
                    else:
                        pos_def = False
                
                curvlst.append(round(K3-1/1000, 3))
            
    return curvlst

def curvatures(A, P, N=inf, onesps=[], q=None):
    A = np.array(A)
    P = np.array(P)
    if len(onesps) == 0:
        onesps = onespheres(A)
    if q == None:
        q = len(A)
    
    switch = False
    for i in range(q):
        for j in range(q):
            if A[i, j] != 0 and P[i, j] < 10**(-5):
                P[i, j] = 0
                switch = True
                
    curvlst = []
    P_traceless = P-np.diag(np.diag(P))
    D_x = np.matmul(P_traceless, np.ones(q))
    P_t_2 = np.matmul(P_traceless, P_traceless)
    twosp = np.matmul(A, A)
    for i in range(q):
        for j in range(q):
            if i == j:
                twosp[i, j] = 0
            if A[i, j] == 1:
                twosp[i, j] = 0
            if twosp[i, j] != 0:
                twosp[i, j] = 1
    Z = twosp*P_t_2
    
    if switch == False:
        for i in range(q):
            for j in range(q):
                if twosp[i, j] != 0:
                    Z[i, j] = 1/Z[i, j]
        sum1 = 3/2*np.matmul(P, twosp)
        sum2 = 3/2*np.matmul(P_traceless, A)
        sum3 = 2*np.matmul(Z, np.transpose(np.square(P)))
        sum4 = 2*np.matmul([[[P[i, z]*P[j, z] for z in range(q)] for j in range(q)]
                            for i in range(q)], np.transpose(Z))
        for x in range(q):
            m = onesps[-1][x]
            if m == 0:
                curvlst.append(0)
            else:
                onesp = onesps[x]
                A_N = np.array([[-2/N*(P[x, i]*P[x, j])**0.5 for j in onesp] for i in onesp])
                for i in range(m):
                    A_N[i, i] += (P[x, onesp[i]]+3/2*P[onesp[i], x]-1/2*D_x[x]+sum1[onesp[i], x]
                                  +sum2[onesp[i], x]-P[x, onesp[i]]*sum3[x, onesp[i]]
                                  +1/2*P_t_2[x, onesp[i]]/P[x, onesp[i]])
                for i in range(m):
                    for j in range(m):
                        if i != j:
                            A_N[i, j] += (P[x, onesp[i]]*P[x, onesp[j]]-P[x, onesp[i]]*P[onesp[i], onesp[j]]
                                          -P[x, onesp[j]]*P[onesp[j], onesp[i]]
                                          -P[x, onesp[i]]*P[x, onesp[j]]*sum4[onesp[i], onesp[j], x])
                            A_N[i, j] /= np.sqrt(P[x, onesp[i]]*P[x, onesp[j]])
                curvlst.append(la.eigvalsh(A_N)[0])

    else:
        for i in range(q):
            for j in range(q):
                if Z[i, j] != 0:
                    Z[i, j] = 1/Z[i, j]
        sum1 = 3/2*np.matmul(P, twosp)
        sum2 = 3/2*np.matmul(P_traceless, A)
        sum3 = 2*np.matmul(Z, np.transpose(np.square(P_traceless)))
        sum4 = 2*np.matmul([[[P[i, z]*P[j, z] for z in range(q)] for j in range(q)]
                            for i in range(q)], np.transpose(Z))
        for x in range(q):
            m = onesps[-1][x]
            if m == 0:
                curvlst.append(0)
            else:
                onesp = onesps[x]
                Q = np.zeros((m, m))
                for i in range(m):
                    Q[i, i] = 1/2*(P[x, onesp[i]]*(P[x, onesp[i]]+3/2*P[onesp[i], x]
                                                   -1/2*D_x[x]+sum1[onesp[i], x]+sum2[onesp[i], x]
                                                   -P[x, onesp[i]]*sum3[x, onesp[i]])+1/2*P_t_2[x, onesp[i]])
                for i in range(m):
                    for j in range(m):
                        if i != j:
                            Q[i, j] = 1/2*(P[x, onesp[i]]*P[x, onesp[j]]-P[x, onesp[i]]*P[onesp[i], onesp[j]]
                                           -P[x, onesp[j]]*P[onesp[j], onesp[i]]
                                           -P[x, onesp[i]]*P[x, onesp[j]]*sum4[onesp[i], onesp[j], x])
                        
                dim_mat = 1/N*np.array([[P[x, i]*P[x, j] for j in onesp] for i in onesp])
                Q_N = Q - dim_mat
                gamma = 1/2*np.diag([P[x, i] for i in onesp])               
                
                error = 10**(-5)
                
                pos_def = True
                if N >= 2:
                    K0 = -min(D_x+np.diag(P))+1
                else:
                    K0 = -min(D_x+np.diag(P))+1-2*D_x[x]/N                
                
                while pos_def == True:
                    if la.eigvalsh(Q_N - K0*gamma)[0] >= -error:
                        K0 += 1
                    else:
                        pos_def = False
                                
                pos_def = True
                K1 = K0 - 9/10
                while pos_def == True and K1 <= K0:
                    if la.eigvalsh(Q_N - K1*gamma)[0] >= -error:
                        K1 += 1/10
                    else:
                        pos_def = False
                        
                pos_def = True
                K2 = K1 - 9/100
                while pos_def == True and K2 <= K1:
                    if la.eigvalsh(Q_N - K2*gamma)[0] >= -error:
                        K2 += 1/100
                    else:
                        pos_def = False
                        
                pos_def = True
                K3 = K2 - 9/1000
                while pos_def == True and K3 <= K2:
                    if la.eigvalsh(Q_N - K3*gamma)[0] >= -error:
                        K3 += 1/1000
                    else:
                        pos_def = False
                
                curvlst.append(round(K3-1/1000, 3))
            
    return curvlst

# 'calc_curvatures' calculates curvatures of vertices using the output of 'curv_flow' or 'norm_curv_flow'.
# It relies heavily on 'curvatures'
# It returns curvature values in a format usable in 'display_curvatures'.
#
# Input:
# A: adjacency matrix of the graph.
# P_list: list of matrices of transition rates as returned by 'curv_flow'/'norm_curv_flow'.
# N: dimension parameter to be used in calculation. Default value is infinity.
# k: To save computation time, k can be set as a positive integer > 1
# Then curvatures of the vertices of only every kth matrix in P_list is calculated, not every matrix.
# 
# Output:
# Each row represents a vertex
# The ith entry of that row is the curvature value of that vertex at the ith time increment.
def calc_curvatures(A, P_list, N=inf, k=1):
    s = len(A)
    M = len(P_list)
    m = (M+k-1)//k
    onesps = onespheres(A)
    curvlst = [_ for _ in range(m)]
    for i in range(m):
        curvlst[i] = curvatures(A, P_list[k*i], N, onesps, s)
    return np.transpose(curvlst)

# 'K_inf' returns the upper curvature bounds for a vertices in a Markov chain.
# It is an option for C_x(t) as detailed in the paper, and is the choice for the Markov-preserving flow.
# 
# Inputs:
# A: adjacency matrix of the graph.
# P: matrix of transition rates of the graph.
#
# Output:
# A NumPy 1 x n array with entries equal to the upper curvature bound K^0_{P,\infty}.
def K_inf(A, P):
    s = len(P)
    D = [1-P[x, x] for x in range(s)]
    P_2 = np.matmul(P, P)
    sum2 = np.matmul(P_2, np.transpose(A))
    curv = [_ for _ in range(s)]
    for x in range(s):
        if D[x] != 0:
            curv[x] = 1/(2*D[x])*(4*(P_2[x, x]-P[x, x]**2)+sum2[x, x]-P[x, x]*(1-P[x, x]))-P[x, x]/2
        else:
            curv[x] = 0
    return curv

# 'calc_curv_upper_bound' is exactly analogous to 'calc_curvatures' above
# It instead calculates the curvatures' upper bound.
# Note however that this uses 'K_inf' rather than 'curvatures'.
# See above annotations for 'calc_curvatures' for details.
def calc_curv_upper_bound(A, P_list, N=inf, k=1):
    A = np.array(A)
    s = len(A)
    M = len(P_list)
    m = (M+k-1)//k
    curvlst = [_ for _ in range(m)]
    D = np.array([1-P_list[0][x, x] for x in range(s)])
    for i in range(m):
        curvlst[i] = K_inf(A, P_list[k*i]) - 2*D/N
    return np.transpose(curvlst)

##################################################################
#
# Display routines
#
##################################################################

# 'display_curvatures' produces plots showing the evolution of the curvature under the flow
# This is designed to be used using the output of 'calc_curvatures' and 'calc_curv_upper_bound'
# These in turn uses the fundamental function 'curv_flow' or 'norm_curv_flow'
#
# Inputs:
# curv: This should be in the same array format that 'calc_curvatures' (detailed below) returns it.
# dt: This is the time increment in the original curvature flow calculation
# is_Markovian: This determines only whether horizontal dotted lines are produced on the plot.
# These would be at curvature = -1, 2; the bounds of B-E curvature for a Markov chain if the dimension N >= 2.
# N: dimension used in the curvature calculation (calc_curvatures). 
# k: as set in 'calc_curvatures'/'calc_curv_upper_bound'. This ensures that the time axis is correctly scaled.
# curv_bound: like 'curv', this should have the same format as returned by 'calc_curv_upper_bound'.
# If unspecified, the code produces no plots with reference to this bound.
# vertex_list: a list of the vertices whose curvatures are to be plotted.
# If unspecified, a plot is made for every vertex. 
#
# Output:
# MatPlotLib plots showing the evolution of the B-E curvature of the prescribed vertices.
def display_curvatures(curv, dt=0.3, is_Markovian=True, N=inf, k=1, curv_bound=[], vertex_list=[]):
    if len(vertex_list) == 0:
        vertex_list = np.arange(len(curv))
        
    delta = k*dt
    n = len(curv[0])
    t_list = [delta*i for i in range(n)]
    minus_ones = [-1 for _ in range(n)]
    zeros = [0 for _ in range(n)]
    twos = [2 for _ in range(n)]
    
    comparison = True
    if len(curv_bound) == 0:
        comparison = False

    for i in vertex_list:
        if comparison == True:
            plt.plot(t_list, curv[i])
            plt.plot(t_list, curv_bound[i])
            plt.title('Vertex {} curvature and curvature upper bound'.format(i))
        else:
            plt.plot(t_list, curv[i][:n])
            plt.title('Vertex {} curvature'.format(i))
        if N >= 2:
            plt.plot(t_list, zeros, '--', linewidth=0.8)
        if is_Markovian == True and N >= 2:
            plt.plot(t_list, minus_ones, '--', linewidth=0.8)
            plt.plot(t_list, twos, '--', linewidth=0.8)
        plt.show()

# 'display_trans_rates' produces a plot of the evolution of transition rates on each vertex.
#
# Inputs:
# A: the adjacency matrix of the graph.
# P_list: the list of matrices of transition rates, as calculated by a curvature flow function.
# t_max: the time until which the evolution should be displayed.
# dt: the time increment used in the calculation of P_list.
# vertex_list: a list of the vertices whose curvatures are to be plotted.
# If unspecified, a plot is made for every vertex.
# 
# Output:
# A plot of the evolution of the transition rates from the specified vertices of the graph
def display_trans_rates(A, P_list, dt=0.3, vertex_list=[]):
    if len(vertex_list) == 0:
        vertex_list = np.arange(len(A))
        
    s = len(A)
    onesps = onespheres(A)
    n = len(P_list)
    t_list = [dt*i for i in range(n)]
    zeros = [0 for _ in range(n)]
    ones = [1 for _ in range(n)]
    for i in vertex_list:
        plt.plot(t_list, zeros, '--', linewidth=0.8)
        plt.plot(t_list, ones, '--', linewidth=0.8)
        for j in onesps[i]:
            plt.plot(t_list, [P_list[m][i, j] for m in range(n)], label="{}_{}".format(i, j))
        plt.legend()
        plt.title("Probability transitions for vertex {}".format(i))
        plt.show()

# The following three functions determine the values of variables used in display_weighted_graph.
def line_angle(a, b):
    if a[0] == b[0]:
        return 90
    theta = math.atan((b[1]-a[1])/(b[0]-a[0]))
    return math.degrees(theta)

def label_position(a, b, ratio):
    a = np.array(a)
    b = np.array(b)
    theta = math.radians(line_angle(a, b))
    point = a+ratio*(b-a)
    vec = np.array([math.cos(theta+1/2*math.pi), math.sin(theta+1/2*math.pi)])
    return point+1/25*vec

def arrow_position(a, b):
    a = np.array(a)
    b = np.array(b)
    point1 = a+1/5*(b-a)
    point2 = b+1/5*(a-b)
    return point1, point2

# 'display_weighted_graph' products a MatPlotLib plot of a graph, with vertices arranged in a circle.
# Note that this only works well for unmixed graphs.
# 
# Inputs:
# A: the adjacency matrix describing the topology of the graph
# P: the matrix of transition rates
# title: the title of the plot. Default is no title.
# threshold: transition rates with values lower than this will be treated as if zero.
# display_options: a list of length 4 with the following entries:
# Entry 0: (size) the size of the plot.
# Entry 1: (display transition rates) Boolean input.
#          If True, transition rates are plotted along the edge they correspond to. 
# Entry 2: (decimal_places): the number of decimal places you want the numbers to have.
# Entry 3: (transition rate shift): Can reposition of transition rate labels as described in the paper.
# laziness: If laziness == True, the laziness of each vertex is displayed next to it.
#
# Output:
# Plot of the graph with vertices arranged in a circle
# The following colouring scheme is applied for an edge (x, y):
# Black, dotted lines have both p_{xy} and p_{yx}  equal to zero/below threshold.
# Red, dashed lines have one of p_{xy} and p_{yx} equal to zero/below threshold, one above threshold.
# Green, solid lines have both p_{xy} and p_{yx} above threshold.
def display_weighted_graph(A, P, title=None, threshold=10**(-3), 
                           display_options=[10, True, 2, []], laziness=False):
    
    A = np.array(A)
    P = np.array(P)
    
    t = threshold
    
    T = display_options

    n = len(A)
    removed = []
    one_way = []
    remain = []
    for i in range(n):
        for j in range(i):
            if A[i, j] == 1:
                if P[i, j] < t and P[j, i] < t:
                    removed.append([j, i])
                elif P[i, j] >= t and P[j, i] >= t:
                    remain.append([j, i])
                elif P[i, j] >= t:
                    one_way.append([i, j])
                else:
                    one_way.append([j, i])

    p = len(removed)
    q = len(one_way)
    r = len(remain)
    
    x_locations = [math.cos(2*math.pi*i/n) for i in range(n)]
    y_locations = [math.sin(2*math.pi*i/n) for i in range(n)]
    
    ratios = 1/6*np.ones((n, n))
    
    for shift in T[3]:
        if shift[0] < n and shift[1] < n:
            ratios[shift[0], shift[1]] = shift[2]
            ratios[shift[1], shift[0]] = shift[3]
    
    fig = plt.figure(figsize=(T[0], T[0]))
    ax = fig.add_subplot(111)
    ax.set_xlim(-1.4, 1.4)
    ax.set_ylim(-1.4, 1.4)
    for i in range(p):
        plt.plot([x_locations[removed[i][0]], x_locations[removed[i][1]]], 
                 [y_locations[removed[i][0]], y_locations[removed[i][1]]], 
                 ':', linewidth=1.5, marker='o', color='k')
    for i in range(q):
        plt.plot([x_locations[one_way[i][0]], x_locations[one_way[i][1]]], 
                 [y_locations[one_way[i][0]], y_locations[one_way[i][1]]], 
                 '--', linewidth=1.8, marker='o', color='r')
    for i in range(r):
        plt.plot([x_locations[remain[i][0]], x_locations[remain[i][1]]],
                 [y_locations[remain[i][0]], y_locations[remain[i][1]]], 
                 '-', linewidth=1.8, marker='o', color='g')
    
    for i in range(n):
        ax.annotate('v{}'.format(i),xy=(1.1*x_locations[i], 1.1*y_locations[i]), 
                    fontsize=20, ha='center', va='center')
        if laziness == True:
            ax.annotate(str(np.around(P[i, i], 2)),xy=(1.3*x_locations[i], 1.3*y_locations[i]), 
                        fontsize=20, ha='center', va='center')
    for edge in one_way:
        a = [x_locations[edge[0]], y_locations[edge[0]]]
        b = [x_locations[edge[1]], y_locations[edge[1]]]
        position = label_position(a, b, ratios[edge[0]][edge[1]])
        if T[1] == True:
            ax.text(position[0], position[1], str(round(P[edge[0], edge[1]], T[2])).strip('0'), 
                    fontsize = 15, ha='center', va='center', rotation=line_angle(a, b))
        arrows = arrow_position(a, b)
# determines orientation of arrow
        if a[0] > b[0]:
            dir = 1
        elif a[0] == b[0]:
            if a[1] < b[1]:
                dir = -1
            else:
                dir = 1
        else:
            dir = -1
        ax.text(arrows[0][0], arrows[0][1], 'V', fontsize = 15, ha='center', va='center', 
                rotation=line_angle(a, b)-dir*90)
        ax.text(arrows[1][0], arrows[1][1], 'V', fontsize = 15, ha='center', va='center', 
                rotation=line_angle(a, b)-dir*90)
    if T[1] == True:
        for edge in remain:
            a = [x_locations[edge[0]], y_locations[edge[0]]]
            b = [x_locations[edge[1]], y_locations[edge[1]]]
            position1 = label_position(a, b, ratios[edge[0]][edge[1]])
            position2 = label_position(b, a, ratios[edge[1]][edge[0]])
            str1 = str(round(P[edge[0], edge[1]], T[2])).strip('0')
            str2 = str(round(P[edge[1], edge[0]], T[2])).strip('0')
            if str1 == '.':
                str1 = '.0'
            if str2 == '.':
                str2 = '.0'
            ax.text(position1[0], position1[1], str1, fontsize = 15, ha='center', va='center', 
                    rotation=line_angle(a, b))
            ax.text(position2[0], position2[1], str2, fontsize = 15, ha='center', va='center', 
                    rotation=line_angle(a, b))
    plt.axis('off')
    if title != None:
        plt.title(title, fontsize=20)
    plt.show()              
        
##################################################################
#
# Setup to run examples
#
##################################################################

dt = 0.1                  # time increment in the Runge-Kutta (RK4) algorithm 
stoch_corr = False        # automatic stochastic correction in the RK4 algorithm
norm_tolerance = 0.001    # threshold to apply stochastic correction
threshold = 0.001         # threshold to consider a number numerally as zero
lim_tolerance = 0.001    # threshold to define flow convergence
t_lim = 10000             # maximal flow time 
p = 0.7                   # Erdoes-Renyi probability parameter
k = 1                     # time multiplier for consecutive curvature computations
is_Markov = True          # curvatures are w.r.t. a Markovian weighting scheme
N = inf                   # dimension parameter for curvature computations
laziness = False          # Boolean in the generation of random weighting schemes   

# The following commented-out lines are what originally produced our example in the paper.
# However, here we manually input the A and P_0 from the example.
# A = rand_adj_mat(10, 0.7, False) 
# P = randomizer(A, threshold, laziness)

A = [[0, 1, 1, 1, 0, 1, 1, 1, 0, 1],
     [1, 0, 0, 1, 0, 1, 1, 1, 1, 1],
     [1, 0, 0, 0, 0, 0, 1, 0, 0, 1], 
     [1, 1, 0, 0, 1, 1, 1, 1, 0, 0], 
     [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 
     [1, 1, 0, 1, 0, 0, 1, 0, 0, 0], 
     [1, 1, 1, 1, 0, 1, 0, 1, 0, 0], 
     [1, 1, 0, 1, 0, 0, 1, 0, 1, 0], 
     [0, 1, 0, 0, 0, 0, 0, 1, 0, 1], 
     [1, 1, 1, 0, 0, 0, 0, 0, 1, 0]]

P_0 = [[0,  0.1,  0.08, 0.17, 0,  0.28, 0.21, 0.08, 0,  0.08],
      [0.08, 0,  0,  0.16, 0,  0.2,  0.07, 0.3,  0.04, 0.15], 
      [0.27, 0,  0,  0,  0,  0,  0.3,  0,  0,  0.43],
      [0.02, 0.19, 0,  0,  0.17, 0.17, 0.11, 0.34, 0,  0],
      [0,  0,  0,  1,  0,  0,  0,  0,  0,  0],
      [0.04, 0.21, 0,  0.41, 0,  0,  0.34, 0,  0,  0],
      [0.06, 0.29, 0.14, 0.12, 0,  0.3,  0,  0.09, 0,  0],
      [0.08, 0.31, 0,  0.19, 0,  0,  0.23, 0,  0.19, 0],
      [0,  0.13, 0,  0,  0,  0,  0,  0.25, 0,  0.62],
      [0.1,  0.33, 0.38, 0,  0,  0,  0,  0,  0.19, 0]]

limit = norm_curv_flow_lim(A, P_0, dt, stoch_corr, norm_tolerance, lim_tolerance, t_lim)

t_max=limit[1] # limit[1] is the convergence time as calculated by norm_curv_flow_lim

flow = norm_curv_flow(A, P_0, t_max, dt, stoch_corr, norm_tolerance)

display_weighted_graph(A, P_0, "Initial random weighted graph", threshold)
display_weighted_graph(A, limit[0], "Curvature flow limit", threshold)
display_trans_rates(A, flow, dt, [3, 8])

curvs = calc_curvatures(A, flow, N, k)
curv_bound = calc_curv_upper_bound(A, flow, N, k)
display_curvatures(curvs, dt, is_Markov, N, k, curv_bound, [1, 9])